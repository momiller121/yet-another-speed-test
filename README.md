yet-another-speed-test
======================

Simple Node.js based network speed test with support for IE6

> The primary goal of the project is to create a simple (perhaps, even naive) speed test that is suitable to run within
> an an internal network. Instead of focusing on the validity of the numeric data produced by the client(s)
> the focus is to **support the ability to trend (over time)** the relative client perspective of network performance.
> We also wanted to be able to support old browsers (as far back as IE6) and other standalone HTTP client test clients
> (bash, python, etc.). The test client is bound to a standard request proceedure and then submits it's experience back
> to the server. The results log is intended to be fed to something like LogStash to get some data visualization
> running. We've deliberately avoided the [Navigation Timing API] to meet our client support goals in the browser.

###To install:

(assuming Node.js and npm are installed and on your path...)

git clone (or download zip) then cd into yet-another-speed-test

```sh
$ npm install
```
###To Run
```sh
$ npm start
```
###To Use
Browse to http://127.0.0.1:5000
(before you can reach the test from elsewhere, edit authorizedRanges in config.js)

##Client Request Behaviour
Again, the design intention is to be able to *trend the client experience* of performing a series of HTTP requests.
We recognize that there are a myriad of factors (including the network) that can influence the client experience of
the 'speed'. The default browser based JavaScript client is influenced by the browser it's running on and the machine
specs. Therefore it is recognized that the numeric data generated by this method is not necessarily comparable between
clients. However, given stability of client behaviours and request metrics collected over time, patterns may emerge.

####The 'Latency' Test
The improvised 'latency' test requires the client to request a 37 byte 1x1 pixel transparant gif image. On the browser
client, this is done by defining a new Image object and measurung the interval from setting the src attribute to
triggering the image's onLoad event. This is repeated 12 times with this idea that DNS caching following the initial
request speeds things up. The slowest and the fastest single timings are discarded and the remaining 10 are averaged
to provide this 'latency' value.

####The Download Test
The download test is conducted through a series of requests for increasingly large binary payloads of (somewhat) random
bytes. The client's goal is to meet a data transit threshold time greater than 8 seconds. It is considered good and
desirable client behavior to conduct the entire series of requests on the same HTTP connection using HTTP keep-alive.

Once the server reaches the upper limit of the package sizes it is willing to serve (or the client measures the 8
second threshold, all but the two longest running requests are discarded and the longest are averaged.

####The Upload Test
The upload test operates in a similar pattern to the download test with a similar goal of 8 seconds of transit time. In
the case of upload, it is the client constructing large payloads of random string data. The server measures what is
sent and black-holes the data. The client, again, discards all but the two longest running uploads and averages those.

##Logging
The tool uses Bunyan to log JSON data to disk. Our intent is to run that data into logstash and visualize in
Kabana. The tool creates a familiar *access.log* and a very basic *server.log*. The main trending value comes from the
*results.log* which is populated with data submitted by the clients upon completion of the tests.

[navigation timing api]:http://www.w3.org/TR/navigation-timing/